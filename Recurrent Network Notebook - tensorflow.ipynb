{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFnpYG5WPv8o"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6vfXVQRPv84"
      },
      "outputs": [],
      "source": [
        "%autoreload # When utils.py is updated\n",
        "from utils_resunet_ulstm import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGndvPVSPv86"
      },
      "outputs": [],
      "source": [
        "dm = 'yes'\n",
        "n_dates = 7\n",
        "root_path = 'Dados_SAR/'\n",
        "\n",
        "##LOADING IMAGE SEQUENCE\n",
        "\n",
        "name_img1 = 'img1_raw' \n",
        "name_img2 = 'img2_raw' \n",
        "name_img3 = 'PA_2019_10_08'\n",
        "name_img4 = 'PA_2019_12_07'\n",
        "name_img5 = 'PA_2020_02_05'\n",
        "name_img6 = 'PA_2020_04_05'\n",
        "name_img7 = 'PA_2020_06_04'\n",
        "\n",
        "img1 = load_SAR_image(root_path+'SAR_Sequence/'+name_img1+'.tif').astype(np.float32) \n",
        "img1 = filter_outliers(img1.copy()) \n",
        "print('img1', np.min(img1), np.max(img1))\n",
        "print('image1: ', img1.shape)\n",
        "\n",
        "img2 = load_SAR_image(root_path+'SAR_Sequence/'+name_img2+'.tif').astype(np.float32) \n",
        "img2 = filter_outliers(img2.copy()) \n",
        "print('img2', np.min(img2), np.max(img2))\n",
        "print('image2: ', img2.shape)\n",
        "\n",
        "img3 = load_SAR_image(root_path+'SAR_Sequence/'+name_img3+'.tif').astype(np.float32) \n",
        "img3 = filter_outliers(img3.copy()) \n",
        "print('img3', np.min(img3), np.max(img3))\n",
        "print('image3: ', img3.shape)\n",
        "\n",
        "img4 = load_SAR_image(root_path+'SAR_Sequence/'+name_img4+'.tif').astype(np.float32) \n",
        "img4 = filter_outliers(img4.copy()) \n",
        "print('img4', np.min(img4), np.max(img4))\n",
        "print('image4: ', img4.shape)\n",
        "\n",
        "img5 = load_SAR_image(root_path+'SAR_Sequence/'+name_img5+'.tif').astype(np.float32) \n",
        "img5 = filter_outliers(img5.copy()) \n",
        "print('img5', np.min(img5), np.max(img5))\n",
        "print('image5: ', img5.shape)\n",
        "\n",
        "img6 = load_SAR_image(root_path+'SAR_Sequence/'+name_img6+'.tif').astype(np.float32) \n",
        "img6 = filter_outliers(img6.copy()) \n",
        "print('img6', np.min(img6), np.max(img6))\n",
        "print('image6: ', img6.shape)\n",
        "\n",
        "img7 = load_SAR_image(root_path+'SAR_Sequence/'+name_img7+'.tif').astype(np.float32) \n",
        "img7 = filter_outliers(img7.copy()) \n",
        "print('img7', np.min(img7), np.max(img7))\n",
        "print('image7: ', img7.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2ziwr27hLN_"
      },
      "outputs": [],
      "source": [
        "# Load current reference \n",
        "ref_2020 = 'def_2020' \n",
        "ref_2020 = load_tif_image(root_path+'References/'+ref_2020+'.tif').astype(np.float32)\n",
        "\n",
        "# Load past reference \n",
        "past_ref_2019 = 'def_2008_2019' \n",
        "past_ref_2019 = load_tif_image(root_path+'References/'+past_ref_2019+'.tif').astype(np.float32)\n",
        "\n",
        "past_ref_2007 = 'def_1988_2007'\n",
        "past_ref_2007 = load_tif_image(root_path+'References/'+past_ref_2007+'.tif').astype(np.float32)\n",
        "\n",
        "past_ref = past_ref_2019 + past_ref_2007 \n",
        "past_ref[past_ref >=1 ] = 1\n",
        "np.unique(past_ref)\n",
        "buffer = 2\n",
        "final_mask1 = mask_no_considered(ref_2020, buffer, past_ref)\n",
        "del past_ref_2019, past_ref_2007\n",
        "print(final_mask1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrovxtzrhLOE"
      },
      "outputs": [],
      "source": [
        "# Print percentage of each class (whole image)\n",
        "no_def = len(final_mask1[final_mask1==0])\n",
        "def_ = len(final_mask1[final_mask1==1])\n",
        "pt_def = len(final_mask1[final_mask1==2])\n",
        "print('Percentage of deforestaion class is {:.2f}'.format((def_*100)/(final_mask1.shape[0]*final_mask1.shape[1])))\n",
        "print('Percentage of no-deforestaion class is {:.2f}'.format((no_def*100)/(final_mask1.shape[0]*final_mask1.shape[1])))\n",
        "print('Percentage of past-deforestaion class is {:.2f}'.format((pt_def*100)/(final_mask1.shape[0]*final_mask1.shape[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ig9j0JLhLOI",
        "outputId": "8f6fe2d4-e37c-41c6-dcbb-f650fd708472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5767, 9327, 14)\n",
            "-6.8049436 5.7555103\n"
          ]
        }
      ],
      "source": [
        "image_array1 = np.concatenate((img1, img2, img3, img4, img5, img6, img7), axis = -1).astype(np.float32)\n",
        "del img1, img2, img3, img4, img5, img6, img7\n",
        "\n",
        "h_, w_, channels = image_array1.shape\n",
        "print(image_array1.shape)\n",
        "\n",
        "# Normalization\n",
        "type_norm = 1\n",
        "image_array = normalization(image_array1, type_norm)\n",
        "\n",
        "print(np.min(image_array), np.max(image_array))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHjfvnEvhLOL"
      },
      "outputs": [],
      "source": [
        "tiles_x = 6\n",
        "tiles_y = 10\n",
        "mask_tiles = create_mask(final_mask1.shape[0], final_mask1.shape[1], grid_size=(tiles_x,tiles_y))\n",
        "image_array = image_array[:mask_tiles.shape[0], :mask_tiles.shape[1],:]\n",
        "final_mask1 = final_mask1[:mask_tiles.shape[0], :mask_tiles.shape[1]]\n",
        "ref_2020 = ref_2020[:mask_tiles.shape[0], :mask_tiles.shape[1]]\n",
        "print('mask: ',mask_tiles.shape)\n",
        "print('image stack: ', image_array.shape)\n",
        "print('ref :', final_mask1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avC_kNU_Pv9Q"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(final_mask1, cmap = matplotlib.colors.ListedColormap(['darkblue','darkred','darkgrey']))\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y1Nvx6ohLON"
      },
      "outputs": [],
      "source": [
        "exp = 1\n",
        "path_exp = root_path+'experiments/exp'+str(exp)\n",
        "path_models = path_exp+'/models'\n",
        "path_maps = path_exp+'/pred_maps'\n",
        "\n",
        "if not os.path.exists(path_exp):\n",
        "    os.makedirs(path_exp)   \n",
        "if not os.path.exists(path_models):\n",
        "    os.makedirs(path_models)   \n",
        "if not os.path.exists(path_maps):\n",
        "    os.makedirs(path_maps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmvg66zpPv9V"
      },
      "outputs": [],
      "source": [
        "def reshape_patches_lstm(patches, num_dates):\n",
        "    patches_reshaped = np.zeros((patches.shape[0], num_dates, patches.shape[1], patches.shape[2], patches.shape[3]//num_dates))\n",
        "    for i in range(0, num_dates):\n",
        "        patches_reshaped[:,i,:,:,:] = patches[:,:,:,2*i:(2*i)+2]\n",
        "    #print('original patches: ', patches.shape)\n",
        "    #print('reshaped patches: ', patches_reshaped.shape)\n",
        "    return patches_reshaped\n",
        "\n",
        "def batch_generator(batches, num_dates, image, reference, target_size, number_class):\n",
        "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator.\n",
        "    \"\"\"\n",
        "    image = image.reshape(-1, image.shape[-1])\n",
        "    reference = reference.reshape(final_mask1.shape[0]*final_mask1.shape[1])\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        batch_x = np.squeeze(batch_x.astype('int64'))\n",
        "        #print(batch_x.shape)\n",
        "        batch_img = np.zeros((batch_x.shape[0], target_size, target_size, image.shape[-1]))\n",
        "        batch_ref = np.zeros((batch_x.shape[0], target_size, target_size, number_class))\n",
        "        \n",
        "        for i in range(batch_x.shape[0]):\n",
        "            if np.random.rand()>0.5:\n",
        "                batch_x[i] = np.rot90(batch_x[i], 1)\n",
        "            batch_img[i] = image[batch_x[i]] \n",
        "            batch_ref[i] = tf.keras.utils.to_categorical(reference[batch_x[i]] , number_class)\n",
        "        batch_img = reshape_patches_lstm(batch_img.copy(), num_dates)           \n",
        "        yield (batch_img, batch_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HwChWwzPv9X"
      },
      "outputs": [],
      "source": [
        "weights = [0.2, 0.8, 0]\n",
        "overlap = 0.7\n",
        "patch_size = 128\n",
        "batch_size = 32\n",
        "im_idx = create_idx_image(final_mask1)\n",
        "patches_idx = extract_patches(im_idx, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1,patch_size, patch_size)\n",
        "del im_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7FckFLdhLOR"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "\n",
        "number_class = 3\n",
        "nb_filters = [32, 64, 128]\n",
        "adam = Adam(learning_rate = 1e-3 , beta_1=0.9)\n",
        "loss = weighted_categorical_crossentropy(weights)\n",
        "#input_shape = (channels//2, patch_size, patch_size, 2)\n",
        "\n",
        "f1 =16\n",
        "\n",
        "method = 'ulstm'\n",
        "\n",
        "    \n",
        "if method == 'ulstm':\n",
        "    channels = 2\n",
        "    model = U_ConvLSTM(n_dates, patch_size, patch_size, channels, number_class, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwRsUwdKPv9b"
      },
      "outputs": [],
      "source": [
        "time_tr = []\n",
        "kfold = 6  \n",
        "for tm in range(0,kfold):\n",
        "    print('set: ', tm)\n",
        "    \n",
        "    mask_tr_val = np.load(root_path+'Distribution/mask_dist_'+str(tm)+'.npy')\n",
        "    plt.imshow(mask_tr_val)\n",
        "    patches_mask = extract_patches(mask_tr_val, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1, patch_size, patch_size)\n",
        "    \n",
        "    # Selecting index trn val and test patches idx\n",
        "    idx_trn = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==patch_size**2))\n",
        "    idx_val = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==2*patch_size**2))\n",
        "    del patches_mask\n",
        "\n",
        "    patches_idx_trn = patches_idx[idx_trn]\n",
        "    patches_idx_val = patches_idx[idx_val]\n",
        "    del idx_trn, idx_val\n",
        "    \n",
        "    # Extract patches with at least 2% of deforestation class\n",
        "    X_train = retrieve_idx_percentage(final_mask1, patches_idx_trn, patch_size, 2)\n",
        "    X_valid = retrieve_idx_percentage(final_mask1, patches_idx_val, patch_size, 2)\n",
        "  \n",
        "    print('Number of training patches:  ', len(X_train), 'Number of validation patches', len(X_valid))\n",
        "    del patches_idx_trn, patches_idx_val\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(horizontal_flip = True,\n",
        "                                       vertical_flip = True)\n",
        "    valid_datagen = ImageDataGenerator(horizontal_flip = True, \n",
        "                                       vertical_flip = True)\n",
        "\n",
        "    y_train = np.zeros((len(X_train)))\n",
        "    y_valid = np.zeros((len(X_valid)))\n",
        "\n",
        "    train_gen = train_datagen.flow(np.expand_dims(X_train, axis = -1), y_train,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=True)\n",
        "\n",
        "    valid_gen = valid_datagen.flow(np.expand_dims(X_valid, axis = -1), y_valid,\n",
        "                                  batch_size=batch_size,\n",
        "                                  shuffle=False)\n",
        "    \n",
        "    train_gen_crops = batch_generator(train_gen, n_dates, image_array, final_mask1, patch_size, number_class)\n",
        "    valid_gen_crops = batch_generator(valid_gen, n_dates, image_array, final_mask1, patch_size, number_class)\n",
        "    \n",
        "    \n",
        "    model_i = model\n",
        "    model_i.compile(optimizer=adam, loss=loss, metrics=['accuracy'])\n",
        "    model_i.summary()\n",
        "\n",
        "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min')\n",
        "    checkpoint = ModelCheckpoint(path_models+ '/' + method +'_'+str(tm)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    lr_reduce = ReduceLROnPlateau(factor=0.9, min_delta=0.0001, patience=5, verbose=1)\n",
        "    callbacks_list = [earlystop, checkpoint]\n",
        "    # train the model\n",
        "    start_training = time.time()\n",
        "    history = model_i.fit(train_gen_crops,\n",
        "                        steps_per_epoch=len(X_train)*3//train_gen.batch_size,\n",
        "                        validation_data=valid_gen_crops,\n",
        "                        validation_steps=len(X_valid)*3//valid_gen.batch_size,\n",
        "                        epochs=100,\n",
        "                        callbacks=callbacks_list)\n",
        "    end_training = time.time() - start_training\n",
        "    time_tr.append(end_training)\n",
        "    del model_i, train_gen, valid_gen, train_gen_crops, valid_gen_crops, mask_tr_val\n",
        "    \n",
        "time_tr_array = np.asarray(time_tr)\n",
        "# Save training time\n",
        "np.save(path_exp+'/metrics_tr.npy', time_tr_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7-liDzePv9g"
      },
      "outputs": [],
      "source": [
        "# Test loop\n",
        "time_ts = []\n",
        "n_pool = 3\n",
        "n_rows = 6\n",
        "n_cols = 10\n",
        "rows, cols = image_array.shape[:2]\n",
        "pad_rows = rows - np.ceil(rows/(n_rows*2**n_pool))*n_rows*2**n_pool\n",
        "pad_cols = cols - np.ceil(cols/(n_cols*2**n_pool))*n_cols*2**n_pool\n",
        "print(pad_rows, pad_cols)\n",
        "\n",
        "npad = ((0, int(abs(pad_rows))), (0, int(abs(pad_cols))), (0, 0))\n",
        "image1_pad = np.pad(image_array, pad_width=npad, mode='reflect')\n",
        "\n",
        "h, w, c = image1_pad.shape\n",
        "patch_size_rows = h//n_rows\n",
        "patch_size_cols = w//n_cols\n",
        "num_patches_x = int(h/patch_size_rows)\n",
        "num_patches_y = int(w/patch_size_cols)\n",
        "\n",
        "method = 'ulstm'\n",
        "\n",
        "if method == 'ulstm':\n",
        "    channels = 2\n",
        "    new_model = U_ConvLSTM(time, patch_size_rows, patch_size_cols, channels, number_class, f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHzz5aLaPv9i"
      },
      "outputs": [],
      "source": [
        "for tm in range(0,kfold):\n",
        "    print('time: ', tm)\n",
        "    model = load_model(path_models+ '/' + method +'_'+str(tm)+'.h5', compile=False)\n",
        "\n",
        "    for l in range(1, len(model.layers)):\n",
        "        new_model.layers[l].set_weights(model.layers[l].get_weights())\n",
        "\n",
        "    start_test = time.time()\n",
        "    patch_t = []\n",
        "\n",
        "    for i in range(0,num_patches_y):\n",
        "        for j in range(0,num_patches_x):\n",
        "            patch_ts = image1_pad[patch_size_rows*j:patch_size_rows*(j+1), patch_size_cols*i:patch_size_cols*(i+1), :]\n",
        "            patches_ts_t1 = np.expand_dims(patch_ts[:,:,:2], axis=0)\n",
        "            patches_ts_t2 = np.expand_dims(patch_ts[:,:,2:4], axis=0)\n",
        "            patches_ts_t3 = np.expand_dims(patch_ts[:,:,4:6], axis=0)\n",
        "            patches_ts_t4 = np.expand_dims(patch_ts[:,:,6:8], axis=0)\n",
        "            patches_ts_t5 = np.expand_dims(patch_ts[:,:,8:10], axis=0)\n",
        "            patches_ts_t6 = np.expand_dims(patch_ts[:,:,10:12], axis=0)\n",
        "            patches_ts_t7 = np.expand_dims(patch_ts[:,:,12:14], axis=0)\n",
        "            x_test = np.concatenate((patches_ts_t1, patches_ts_t2, patches_ts_t3 , patches_ts_t4, patches_ts_t5, patches_ts_t6, patches_ts_t7), axis=0)\n",
        "            \n",
        "            predictions_ = new_model.predict(np.expand_dims(x_test, axis=0))\n",
        "            del patch_ts, x_test, patches_ts_t1, patches_ts_t2, patches_ts_t3, patches_ts_t4, patches_ts_t5, patches_ts_t6, patches_ts_t7\n",
        "            patch_t.append(predictions_[:,:,:,1])\n",
        "            del predictions_\n",
        "    end_test =  time.time() - start_test\n",
        "    patches_pred = np.asarray(patch_t).astype(np.float32)\n",
        "\n",
        "    prob_recontructed = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred)\n",
        "    np.save(path_maps+'/'+'prob_'+str(tm)+'.npy',prob_recontructed) \n",
        "\n",
        "    time_ts.append(end_test)\n",
        "    del model, patches_pred\n",
        "time_ts_array = np.asarray(time_ts)\n",
        "# Save test time\n",
        "np.save(path_exp+'/metrics_ts.npy', time_ts_array)    \n",
        "del image_array, image1_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0nUD4KshLOb"
      },
      "outputs": [],
      "source": [
        "prob_rec = np.zeros((final_mask1.shape[0], final_mask1.shape[1], kfold))\n",
        "for tm in range (0, kfold):\n",
        "    print(tm)\n",
        "    prob_map = np.load(path_maps+'/'+'prob_'+str(tm)+'.npy').astype(np.float32)\n",
        "    prob_map = prob_map[:final_mask1.shape[0], :final_mask1.shape[1]]\n",
        "    mask_tr_val = np.load(root_path+'Distribution/mask_dist_'+str(tm)+'.npy')\n",
        "    mask_amazon_ts = mask_tr_val.copy()\n",
        "    mask_amazon_ts[mask_amazon_ts >= 1] = 2\n",
        "    mask_amazon_ts[mask_amazon_ts == 0] = 1\n",
        "    mask_amazon_ts[mask_amazon_ts == 2] = 0\n",
        "\n",
        "    prob_rec[:,:,tm] = prob_map * mask_amazon_ts\n",
        "\n",
        "prob_sum = np.sum(prob_rec, axis = -1)\n",
        "np.save(path_maps+'/prob_sum.npy', prob_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6M7CFxBPv9m"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "OUTPUT MAP\n",
        "\n",
        "no-deforestation (true negatives) =  darkblue\n",
        "deforestation (true positives) = darkred\n",
        "false positives = yellow\n",
        "false negatives = cyan\n",
        "past deforestation = darkgrey\n",
        "\n",
        "\"\"\"\n",
        "threshold = 0.5\n",
        "outmap = color_map(prob_sum, ref_2020, final_mask1, threshold)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(outmap, cmap = matplotlib.colors.ListedColormap(['darkblue','darkred','yellow','c','darkgrey']))\n",
        "plt.axis('off')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn4FdQx-Pv9n"
      },
      "outputs": [],
      "source": [
        "#Calculate metrics\n",
        "prob_sum = np.load(path_maps+'/prob_sum.npy')\n",
        "ref1 = np.ones_like(final_mask1).astype(np.float32)\n",
        "\n",
        "ref1 [final_mask1 == 2] = 0\n",
        "TileMask = np.ones_like(final_mask1).astype(np.float32)\n",
        "\n",
        "#threshold = 0.5\n",
        "metricss = matrics_AA_recall([0.5], prob_sum, final_mask1, TileMask, 156)\n",
        "# Complete NaN values\n",
        "metrics_copy_ = metricss.copy()\n",
        "metrics_copy_ = complete_nan_values(metrics_copy_)\n",
        "\n",
        "Recall_ = metrics_copy_[:,0]\n",
        "Precision_ = metrics_copy_[:,1]\n",
        "F1_Score = metrics_copy_[:,2]\n",
        "\n",
        "print(\"Recall = \", Recall_)\n",
        "print(\"Precision = \", Precision_)\n",
        "print(\"F1 Score = \", F1_Score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}